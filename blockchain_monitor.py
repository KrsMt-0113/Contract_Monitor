"""
Blockchain monitor for detecting contract deployments with retry mechanism
"""
import logging
from web3 import Web3
from web3.middleware import ExtraDataToPOAMiddleware
from typing import List, Dict, Union
import time
from concurrent.futures import ThreadPoolExecutor, as_completed

logger = logging.getLogger(__name__)

# Networks that use Proof of Authority (POA) consensus
POA_NETWORKS = ['polygon', 'bsc', 'linea', 'flare', 'avalanche']


class BlockchainMonitor:
    def __init__(self, rpc_urls: Union[str, List[str]], network_name: str = 'ethereum'):
        # Support both single URL and list of URLs
        if isinstance(rpc_urls, str):
            self.rpc_urls = [rpc_urls]
        else:
            self.rpc_urls = rpc_urls

        self.network_name = network_name
        self.w3 = None
        self.current_rpc_url = None

        # Try to connect to any available RPC endpoint
        self._connect_to_rpc()

        if not self.w3 or not self.w3.is_connected():
            raise ConnectionError(f"Failed to connect to any RPC endpoint for {network_name}")

        logger.info(f"Connected to {network_name} blockchain at {self.current_rpc_url}")
        try:
            current_block = self.w3.eth.block_number
            logger.info(f"[{network_name}] Current block number: {current_block}")
        except Exception as e:
            logger.warning(f"Could not fetch current block number: {e}")

    def _connect_to_rpc(self):
        """Try to connect to RPC endpoints in order"""
        for rpc_url in self.rpc_urls:
            try:
                logger.info(f"[{self.network_name}] Trying to connect to {rpc_url}...")
                w3 = Web3(Web3.HTTPProvider(rpc_url, request_kwargs={'timeout': 10}))

                # Inject POA middleware for networks that use Proof of Authority
                if self.network_name in POA_NETWORKS:
                    w3.middleware_onion.inject(ExtraDataToPOAMiddleware, layer=0)
                    logger.debug(f"[{self.network_name}] Injected POA middleware")

                # Test the connection with a simple call
                if w3.is_connected():
                    try:
                        _ = w3.eth.block_number
                        self.w3 = w3
                        self.current_rpc_url = rpc_url
                        logger.info(f"[{self.network_name}] Successfully connected to {rpc_url}")
                        return
                    except Exception as e:
                        logger.warning(f"[{self.network_name}] Connection test failed for {rpc_url}: {e}")
                        continue
            except Exception as e:
                logger.warning(f"[{self.network_name}] Failed to connect to {rpc_url}: {e}")
                continue

        logger.error(f"[{self.network_name}] Could not connect to any RPC endpoint")

    def _ensure_connection(self, max_retries=3, retry_delay=5):
        """Ensure we have a valid connection, reconnect if needed"""
        if not self.w3 or not self.w3.is_connected():
            logger.warning(f"[{self.network_name}] Connection lost, attempting to reconnect...")

            for retry in range(max_retries):
                self._connect_to_rpc()
                if self.w3 and self.w3.is_connected():
                    logger.info(f"[{self.network_name}] Reconnection successful")
                    return

                if retry < max_retries - 1:
                    wait_time = retry_delay * (2 ** retry)  # æŒ‡æ•°é€€é¿
                    logger.warning(f"[{self.network_name}] Reconnection failed, retrying in {wait_time}s... (attempt {retry + 1}/{max_retries})")
                    time.sleep(wait_time)

            raise ConnectionError(f"[{self.network_name}] Failed to reconnect after {max_retries} attempts")

    def get_latest_block_number(self, max_retries=3) -> int:
        """Get the latest block number with retry logic"""
        for attempt in range(max_retries):
            try:
                self._ensure_connection()
                return self.w3.eth.block_number
            except Exception as e:
                if attempt < max_retries - 1:
                    logger.warning(f"[{self.network_name}] Failed to get block number (attempt {attempt + 1}/{max_retries}): {e}")
                    time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
                else:
                    logger.error(f"[{self.network_name}] Failed to get block number after {max_retries} attempts: {e}")
                    raise

    def get_contract_deployments(self, block_number: int, max_retries=3) -> List[Dict]:
        """
        Get all contract deployments in a specific block with retry logic
        ä½¿ç”¨æ‰¹é‡ trace_block å’Œå¹¶è¡Œå¤„ç†æå‡æ€§èƒ½

        Returns:
            List of dictionaries containing deployment information
        """
        deployments = []

        # é‡è¯•è·å–åŒºå—æ•°æ®
        for attempt in range(max_retries):
            try:
                self._ensure_connection()
                block = self.w3.eth.get_block(block_number, full_transactions=True)
                break  # æˆåŠŸè·å–åŒºå—ï¼Œé€€å‡ºé‡è¯•å¾ªç¯
            except Exception as e:
                if attempt < max_retries - 1:
                    logger.warning(f"[{self.network_name}] Failed to get block {block_number} (attempt {attempt + 1}/{max_retries}): {e}")
                    time.sleep(2 ** attempt)
                else:
                    logger.error(f"[{self.network_name}] Failed to get block {block_number} after {max_retries} attempts: {e}")
                    raise

        if not block.transactions:
            return deployments

        # **ä¼˜åŒ–1: æ‰¹é‡è·å–æ•´ä¸ªåŒºå—çš„ trace (ä¸€æ¬¡ RPC è°ƒç”¨)**
        block_traces = self._get_block_traces(block_number)

        # **ä¼˜åŒ–2: å¹¶è¡Œè·å–æ‰€æœ‰äº¤æ˜“çš„ receipts**
        receipts_map = self._get_receipts_parallel(block.transactions)

        # **ä¼˜åŒ–3: å¹¶è¡Œå¤„ç†æ‰€æœ‰äº¤æ˜“**
        try:
            with ThreadPoolExecutor(max_workers=10) as executor:
                futures = []
                for tx in block.transactions:
                    receipt = receipts_map.get(tx['hash'].hex())
                    if not receipt:
                        continue

                    # æäº¤ä»»åŠ¡åˆ°çº¿ç¨‹æ± 
                    future = executor.submit(
                        self._process_single_transaction,
                        tx, receipt, block_number, block_traces
                    )
                    futures.append(future)

                # æ”¶é›†ç»“æœ
                for future in as_completed(futures):
                    try:
                        tx_deployments = future.result()
                        deployments.extend(tx_deployments)
                    except Exception as e:
                        logger.error(f"[{self.network_name}] Error processing transaction: {e}")

        except Exception as e:
            logger.error(f"[{self.network_name}] Error in parallel processing for block {block_number}: {e}")

        return deployments

    def _get_receipts_parallel(self, transactions: List[Dict], max_workers=10) -> Dict[str, Dict]:
        """å¹¶è¡Œè·å–æ‰€æœ‰äº¤æ˜“çš„ receipts"""
        receipts_map = {}

        def get_receipt(tx_hash):
            try:
                return tx_hash.hex(), self.w3.eth.get_transaction_receipt(tx_hash)
            except Exception as e:
                logger.debug(f"[{self.network_name}] Failed to get receipt for {tx_hash.hex()}: {e}")
                return tx_hash.hex(), None

        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = [executor.submit(get_receipt, tx['hash']) for tx in transactions]

            for future in as_completed(futures):
                try:
                    tx_hash, receipt = future.result()
                    if receipt:
                        receipts_map[tx_hash] = receipt
                except Exception as e:
                    logger.debug(f"[{self.network_name}] Error getting receipt: {e}")

        return receipts_map

    def _process_single_transaction(self, tx: Dict, receipt: Dict, block_number: int,
                                    block_traces: Dict) -> List[Dict]:
        """å¤„ç†å•ä¸ªäº¤æ˜“ï¼Œè¿”å›è¯¥äº¤æ˜“ä¸­çš„æ‰€æœ‰éƒ¨ç½²"""
        deployments = []

        # æ–¹æ³•1: ç›´æ¥éƒ¨ç½²æ£€æµ‹ (tx.to is None)
        if tx['to'] is None and receipt.get('contractAddress'):
            deployment = {
                'contract_address': receipt['contractAddress'],
                'deployer_address': tx['from'],
                'transaction_hash': tx['hash'].hex(),
                'block_number': block_number,
                'network': self.network_name,
                'deployment_type': 'direct',
                'factory_address': None,
                'gas_used': receipt['gasUsed'],
                'status': receipt['status']
            }
            deployments.append(deployment)
            logger.info(f"[{self.network_name}] Found direct deployment: {receipt['contractAddress']} "
                      f"by {tx['from'][:10]}... in block {block_number}")

        # æ–¹æ³•2: å·¥å‚åˆçº¦éƒ¨ç½²æ£€æµ‹ - ä½¿ç”¨é¢„å…ˆè·å–çš„ traces
        elif tx['to'] is not None:
            tx_hash = tx['hash'].hex()

            # ä¼˜å…ˆä½¿ç”¨æ‰¹é‡è·å–çš„ traces
            if block_traces and tx_hash in block_traces:
                logger.info(f"[{self.network_name}] ğŸ” Using trace_block for tx {tx_hash[:10]}...")
                factory_deployments = self._parse_traces_for_deployments(
                    block_traces[tx_hash], tx, receipt, block_number
                )
                deployments.extend(factory_deployments)
            else:
                logger.info(f"[{self.network_name}] âš ï¸  Tx {tx_hash[:10]}... not in block_traces (total: {len(block_traces)}), using fallback")
                # å¦‚æœæ‰¹é‡ trace å¤±è´¥ï¼Œä½¿ç”¨å›é€€æ–¹æ¡ˆ
                factory_deployments = self._fallback_detect_factory_deployments(tx, receipt, block_number)
                deployments.extend(factory_deployments)

        return deployments

    def _get_block_traces(self, block_number: int) -> Dict:
        """
        æ‰¹é‡è·å–æ•´ä¸ªåŒºå—çš„æ‰€æœ‰ trace (ä¸€æ¬¡ RPC è°ƒç”¨)
        ç›¸æ¯”é€ä¸ªäº¤æ˜“è°ƒç”¨ trace_transactionï¼Œè¿™èƒ½å¤§å¹…æå‡æ€§èƒ½

        Returns:
            Dict[tx_hash, List[trace]]: æŒ‰äº¤æ˜“å“ˆå¸Œç»„ç»‡çš„ trace æ•°æ®
        """
        try:
            logger.info(f"[{self.network_name}] Attempting trace_block for block {block_number}")
            # ä½¿ç”¨ trace_block ä¸€æ¬¡æ€§è·å–æ•´ä¸ªåŒºå—çš„ trace
            result = self.w3.provider.make_request('trace_block', [hex(block_number)])
            traces = result.get('result', [])

            if not traces:
                logger.info(f"[{self.network_name}] No traces found for block {block_number}")
                return {}

            # æŒ‰äº¤æ˜“å“ˆå¸Œç»„ç»‡ trace
            traces_by_tx = {}
            for trace in traces:
                tx_hash = trace.get('transactionHash')
                if tx_hash:
                    tx_hash_str = tx_hash if isinstance(tx_hash, str) else tx_hash.hex()

                    if tx_hash_str not in traces_by_tx:
                        traces_by_tx[tx_hash] = []
                    traces_by_tx[tx_hash].append(trace)

            logger.info(f"[{self.network_name}] Got traces for {len(traces_by_tx)} transactions in block {block_number}")
            return traces_by_tx

        except Exception as e:
        # âš ï¸ è¿™é‡Œåº”è¯¥åŒºåˆ†ä¸åŒçš„é”™è¯¯ç±»å‹
            error_msg = str(e).lower()

        # å¦‚æœæ˜¯ method not found,è¯´æ˜èŠ‚ç‚¹ä¸æ”¯æŒ trace_block
            if 'method not found' in error_msg or 'not supported' in error_msg:
                logger.warning(f"[{self.network_name}] trace_block not supported by RPC node")
            else:
                logger.warning(f"[{self.network_name}] trace_block failed for block {block_number}: {e}")

            return {}

    def _parse_traces_for_deployments(self, traces: List[Dict], tx: Dict, receipt: Dict,
                                     block_number: int) -> List[Dict]:
        """ä» trace åˆ—è¡¨ä¸­æå–åˆçº¦éƒ¨ç½²ï¼ˆä½¿ç”¨ trace_block æ ¼å¼ï¼‰"""
        deployments = []

        for trace in traces:
            if trace.get('type') == 'create':
                action = trace.get('action', {})
                result = trace.get('result', {})

                contract_address = result.get('address')
                if not contract_address:
                    continue

                deployment = {
                    'contract_address': contract_address,
                    'deployer_address': action.get('from'),
                    'factory_address': tx['to'],
                    'transaction_hash': tx['hash'].hex(),
                    'block_number': block_number,
                    'network': self.network_name,
                    'deployment_type': 'factory',
                    'gas_used': result.get('gasUsed', 0),
                    'status': receipt['status']
                }
                deployments.append(deployment)

                logger.info(f"[{self.network_name}] Found factory deployment: {contract_address} "
                          f"created by {action.get('from')[:10]}... via factory {tx['to'][:10]}...")

        return deployments

    def _detect_factory_deployments(self, tx: Dict, receipt: Dict, block_number: int) -> List[Dict]:
        """é€šè¿‡å†…éƒ¨äº¤æ˜“æ£€æµ‹å·¥å‚åˆçº¦åˆ›å»ºçš„å­åˆçº¦"""
        deployments = []

        try:
            # ä½¿ç”¨ debug_traceTransaction æˆ– trace_transaction è·å–å†…éƒ¨äº¤æ˜“
            # æ³¨æ„ï¼šéœ€è¦ RPC èŠ‚ç‚¹æ”¯æŒ trace æˆ– debug API
            try:
                # æ–¹æ³•1: Parity/OpenEthereum trace API (æ¨è)
                traces = self.w3.provider.make_request('trace_transaction', [tx['hash'].hex()])

                for trace in traces.get('result', []):
                    # æ£€æŸ¥æ˜¯å¦ä¸º CREATE æˆ– CREATE2 æ“ä½œ
                    if trace.get('type') == 'create':
                        action = trace.get('action', {})
                        result = trace.get('result', {})

                        contract_address = result.get('address')
                        if not contract_address:
                            continue

                        deployment = {
                            'contract_address': contract_address,
                            'deployer_address': action.get('from'),  # å®é™…åˆ›å»ºè€…
                            'factory_address': tx['to'],  # å·¥å‚åˆçº¦
                            'transaction_hash': tx['hash'].hex(),
                            'block_number': block_number,
                            'network': self.network_name,
                            'deployment_type': 'factory',
                            'gas_used': result.get('gasUsed', 0),
                            'status': receipt['status'],
                            'init_code': action.get('init', '')[:20] + '...'  # è®°å½•éƒ¨åˆ†åˆå§‹åŒ–ä»£ç 
                        }
                        deployments.append(deployment)

                        logger.info(f"[{self.network_name}] Found factory deployment via trace: {contract_address} "
                                  f"created by {action.get('from')[:10]}... via factory {tx['to'][:10]}...")

            except Exception as e:
                # å¦‚æœ trace API ä¸å¯ç”¨ï¼Œå°è¯•ä½¿ç”¨ debug API
                logger.debug(f"[{self.network_name}] trace_transaction not available, trying debug_traceTransaction: {e}")

                try:
                    # æ–¹æ³•2: Geth debug API (è¾ƒæ…¢ä½†æ›´é€šç”¨)
                    trace = self.w3.provider.make_request('debug_traceTransaction',
                                                          [tx['hash'].hex(),
                                                           {'tracer': 'callTracer'}])

                    deployments.extend(self._parse_call_trace(trace.get('result', {}), tx, receipt, block_number))

                except Exception as e2:
                    logger.debug(f"[{self.network_name}] debug_traceTransaction also failed: {e2}")
                    # å¦‚æœä¸¤ç§æ–¹æ³•éƒ½ä¸å¯ç”¨ï¼Œå›é€€åˆ°åŸæ¥çš„æ–¹æ³•
                    return self._fallback_detect_factory_deployments(tx, receipt, block_number)

        except Exception as e:
            logger.error(f"[{self.network_name}] Error in trace-based factory detection: {e}")

        return deployments

    def _parse_call_trace(self, call_trace: Dict, tx: Dict, receipt: Dict, block_number: int) -> List[Dict]:
        """è§£æ callTracer æ ¼å¼çš„è¿½è¸ªæ•°æ®"""
        deployments = []

        def extract_creates(trace: Dict, parent_address: str = None):
            """é€’å½’æå– CREATE æ“ä½œ"""
            call_type = trace.get('type', '').upper()

            if call_type in ['CREATE', 'CREATE2']:
                contract_address = trace.get('to')
                if contract_address:
                    deployment = {
                        'contract_address': contract_address,
                        'deployer_address': trace.get('from'),
                        'factory_address': parent_address or tx['to'],
                        'transaction_hash': tx['hash'].hex(),
                        'block_number': block_number,
                        'network': self.network_name,
                        'deployment_type': 'factory',
                        'gas_used': int(trace.get('gasUsed', '0x0'), 16) if isinstance(trace.get('gasUsed'), str) else trace.get('gasUsed', 0),
                        'status': receipt['status']
                    }
                    deployments.append(deployment)

                    logger.info(f"[{self.network_name}] Found {call_type} deployment: {contract_address} "
                              f"by {trace.get('from')[:10]}...")

            # é€’å½’å¤„ç†å­è°ƒç”¨
            for call in trace.get('calls', []):
                extract_creates(call, trace.get('to'))

        extract_creates(call_trace)
        return deployments

    def _fallback_detect_factory_deployments(self, tx: Dict, receipt: Dict, block_number: int) -> List[Dict]:
        """å›é€€æ–¹æ¡ˆï¼šå½“ trace API ä¸å¯ç”¨æ—¶ä½¿ç”¨"""
        # è¿™é‡Œæ”¾ä½ åŸæ¥çš„åŸºäº logs å’Œå­—èŠ‚ç æ£€æŸ¥çš„å®ç°
        deployments = []
        seen_addresses = set()

        SKIP_ADDRESSES = {
            '0x0000000000000000000000000000000000000000',
            *[f'0x000000000000000000000000000000000000000{i}' for i in range(1, 20)]
        }

        try:
            for log in receipt.get('logs', []):
                address = log['address']

                if (address in seen_addresses or
                    address == tx['to'] or
                    address in SKIP_ADDRESSES):
                    continue

                seen_addresses.add(address)

                try:
                    code = self.w3.eth.get_code(address)
                    if not code or code == b'\x00' or len(code) <= 2:
                        continue

                    try:
                        previous_code = self.w3.eth.get_code(address, block_identifier=block_number - 1)
                        if previous_code and len(previous_code) > 2:
                            continue
                    except Exception:
                        pass

                    deployment = {
                        'contract_address': address,
                        'deployer_address': tx['from'],
                        'factory_address': tx['to'],
                        'transaction_hash': tx['hash'].hex(),
                        'block_number': block_number,
                        'network': self.network_name,
                        'deployment_type': 'factory',
                        'gas_used': receipt['gasUsed'],
                        'status': receipt['status']
                    }
                    deployments.append(deployment)

                except Exception as e:
                    logger.debug(f"[{self.network_name}] Error checking address {address}: {e}")
                    continue

        except Exception as e:
            logger.debug(f"[{self.network_name}] Error in fallback factory detection: {e}")

        return deployments

    def get_deployments_in_range(self, start_block: int, end_block: int, max_workers=5) -> List[Dict]:
        """
        Get all contract deployments in a range of blocks (å¹¶è¡Œå¤„ç†)

        Args:
            start_block: Starting block number (inclusive)
            end_block: Ending block number (inclusive)
            max_workers: å¹¶è¡Œå¤„ç†çš„æœ€å¤§çº¿ç¨‹æ•°

        Returns:
            List of all deployments found
        """
        all_deployments = []
        failed_blocks = []

        # **å¹¶è¡Œå¤„ç†å¤šä¸ªåŒºå—**
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰åŒºå—çš„å¤„ç†ä»»åŠ¡
            future_to_block = {
                executor.submit(self.get_contract_deployments, block_num): block_num
                for block_num in range(start_block, end_block + 1)
            }

            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_block):
                block_num = future_to_block[future]
                try:
                    deployments = future.result()
                    all_deployments.extend(deployments)
                except Exception as e:
                    logger.error(f"[{self.network_name}] Error processing block {block_num}: {e}")
                    failed_blocks.append(block_num)

        if failed_blocks:
            logger.warning(f"[{self.network_name}] Failed to process {len(failed_blocks)} block(s): {failed_blocks}")

        # æŒ‰åŒºå—å·æ’åºç»“æœ
        all_deployments.sort(key=lambda x: x['block_number'])

        return all_deployments

    def stream_deployments_in_range(self, start_block: int, end_block: int,
                                     deployment_queue, max_workers=10):
        """
        æµå¼å¤„ç†åŒºå—èŒƒå›´ï¼Œå°†éƒ¨ç½²ç»“æœå®æ—¶æ¨é€åˆ°é˜Ÿåˆ—ï¼ˆç”Ÿäº§è€…æ¨¡å¼ï¼‰
        è¿™æ ·å¯ä»¥è¾¹è·å–åŒºå—è¾¹å¤„ç†ï¼Œæ¶ˆé™¤ä¸²è¡Œç­‰å¾…

        Args:
            start_block: Starting block number (inclusive)
            end_block: Ending block number (inclusive)
            deployment_queue: Queue to push deployment results to
            max_workers: Maximum number of parallel block processing workers
        """
        def process_single_block(block_num):
            """å¤„ç†å•ä¸ªåŒºå—å¹¶å°†ç»“æœæ¨å…¥é˜Ÿåˆ—"""
            try:
                deployments = self.get_contract_deployments(block_num)

                # å°†æ¯ä¸ªéƒ¨ç½²æ¨é€åˆ°é˜Ÿåˆ—
                for deployment in deployments:
                    deployment_queue.put(('deployment', deployment))

                # æ¨é€è¿›åº¦æ›´æ–°
                deployment_queue.put(('block_processed', (self.network_name, block_num)))

            except Exception as e:
                logger.error(f"[{self.network_name}] Error processing block {block_num}: {e}")
                deployment_queue.put(('error', (self.network_name, block_num, str(e))))

        # å¹¶è¡Œå¤„ç†æ‰€æœ‰åŒºå—
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = [
                executor.submit(process_single_block, block_num)
                for block_num in range(start_block, end_block + 1)
            ]

            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            for future in as_completed(futures):
                try:
                    future.result()
                except Exception as e:
                    logger.error(f"[{self.network_name}] Block processing task failed: {e}")

